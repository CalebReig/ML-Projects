{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Customer Personality Analysis - Prediction of Customer Response to Marketing</h1>\n",
    "<h2>Table of Contents</h2>\n",
    "\n",
    "* [Problem Statement](#1)\n",
    "    \n",
    "* [Project Objectives](#2)\n",
    "    \n",
    "* [Importing Libraries and Read In Dataset](#3)\n",
    "    \n",
    "* [Split Dataset and Balance Classes](#4)   \n",
    "    \n",
    "* [Create Models](#5) \n",
    "      \n",
    "* [Ensemble the Models](#6)\n",
    "\n",
    "* [Conclusions](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h2>Problem Statement</h2>\n",
    "<p>\n",
    "    Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "\n",
    "Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.\n",
    "</p>\n",
    "<p>\n",
    "    Source: <a href=\"https://www.kaggle.com/imakash3011/customer-personality-analysis\">Kaggle - Customer Personality Analysis</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h2>Project Objectives</h2>\n",
    "<ol>\n",
    "    <li>Determine customer traits and behaviors</li>\n",
    "    <li>Group similar customers based on traits and behaviors</li>\n",
    "    <li>Create predictive model to predict which customers will respond to marketting campaigns</li>\n",
    "</ol>\n",
    "<h5>In this notebook I will focus on the 3rd objective. I will read in the new cleaned dataset from a previous notebook\n",
    "    (1.Feat_Eng_EDA.ipynb). Then, I will clean and standardize the data before splitting it into a train, test, and \n",
    "    validation set. To balnace the classes (responded and didnt respond) I will be using a technique called SMOTE. Using this new dataset, I will create 5 weak models and evaluate each. Using these 5 models, I will\n",
    "create an ensemble model which will take a majority vote as to what to classify the customer. Finally, I will present my\n",
    "conclusions.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h2>Importing Libraries and Read In Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np #linear algebra\n",
    "import pandas as pd #data processing\n",
    "import matplotlib.pyplot as plt #data viz\n",
    "import seaborn as sns #data viz\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #preprocessing\n",
    "from sklearn.compose import ColumnTransformer #preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #data split, grid search\n",
    "from imblearn.over_sampling import SMOTE #balance classes\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn.svm import SVC #support vector machine\n",
    "from sklearn.neighbors import KNeighborsClassifier #knn\n",
    "from sklearn.naive_bayes import GaussianNB #bayes\n",
    "from xgboost import XGBClassifier #gradient boosting tree\n",
    "from sklearn.metrics import accuracy_score, recall_score #calculates accuracy, recall\n",
    "from sklearn.ensemble import VotingClassifier#ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>Age</th>\n",
       "      <th>Days_Since_Customer</th>\n",
       "      <th>Fam_Size</th>\n",
       "      <th>Num_Accepted</th>\n",
       "      <th>MntTotal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3509.686794</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2663.686794</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3010.686794</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2603.686794</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>PhD</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2859.686794</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Education   Income  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
       "ID                                                                         \n",
       "5524  Graduation  58138.0       58       635         88              546   \n",
       "2174  Graduation  46344.0       38        11          1                6   \n",
       "4141  Graduation  71613.0       26       426         49              127   \n",
       "6182  Graduation  26646.0       26        11          4               20   \n",
       "5324         PhD  58293.0       94       173         43              118   \n",
       "\n",
       "      MntFishProducts  MntSweetProducts  MntGoldProds  NumDealsPurchases  \\\n",
       "ID                                                                         \n",
       "5524              172                88            88                  3   \n",
       "2174                2                 1             6                  2   \n",
       "4141              111                21            42                  1   \n",
       "6182               10                 3             5                  2   \n",
       "5324               46                27            15                  5   \n",
       "\n",
       "      NumWebPurchases  NumCatalogPurchases  NumStorePurchases  \\\n",
       "ID                                                              \n",
       "5524                8                   10                  4   \n",
       "2174                1                    1                  2   \n",
       "4141                8                    2                 10   \n",
       "6182                2                    0                  4   \n",
       "5324                5                    3                  6   \n",
       "\n",
       "      NumWebVisitsMonth  Complain  Response  Age  Days_Since_Customer  \\\n",
       "ID                                                                      \n",
       "5524                  7         0         1   64          3509.686794   \n",
       "2174                  5         0         0   67          2663.686794   \n",
       "4141                  4         0         0   56          3010.686794   \n",
       "6182                  6         0         0   37          2603.686794   \n",
       "5324                  5         0         0   40          2859.686794   \n",
       "\n",
       "      Fam_Size  Num_Accepted  MntTotal  \n",
       "ID                                      \n",
       "5524         1             0      2252  \n",
       "2174         3             0        38  \n",
       "4141         2             0      1202  \n",
       "6182         3             0        64  \n",
       "5324         3             0       595  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in previously cleaned dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "clean_data = pd.read_csv('data/mc_fe.csv', index_col='ID')\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>The data will need some preprocessing before the predictive model is created. 'Education' needs to be encoded and the other\n",
    "    columns need to be scaled. Also, the target column 'Repsonse' needs to be removed from the dataset.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n",
      "[ 0.          0.          1.          0.          0.          0.23532677\n",
      "  0.30703926  0.98378127  1.55157698  1.67970233  2.46214705  1.4765001\n",
      "  0.84320691  0.34941394  1.40930394  2.51089024 -0.55078479  0.69390374\n",
      " -0.09728167  0.98534473  1.97674456 -1.75911463 -0.43903713  1.4669731 ]\n"
     ]
    }
   ],
   "source": [
    "#Remove the 'Response' column because it is the target of future predictive model\n",
    "X, y = clean_data.drop('Response', axis=1).values, clean_data['Response'].values\n",
    "\n",
    "#Creates a column transformer that sends 'Education' to be encoded and rest scaled\n",
    "ct = ColumnTransformer([\n",
    "    ('catagoric', OneHotEncoder(), [0]),\n",
    "    ('numeric', StandardScaler(), list(range(1, len(X.T))))\n",
    "])\n",
    "\n",
    "#Sends the data through the column transformer\n",
    "X_transformed = ct.fit_transform(X)\n",
    "print('Preprocessed Data:')\n",
    "print(X_transformed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h2>Split Dataset and Balance Classes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Each Dataset:\n",
      "Training Set: 1568\n",
      "Validation Set: 336\n",
      "Test Set: 336\n"
     ]
    }
   ],
   "source": [
    "#Split into train (70%) and test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=8)\n",
    "\n",
    "#Split the test set into 2 sets; 1 for test, 1 for validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=8)\n",
    "\n",
    "#Display length of each set\n",
    "print('Length of Each Dataset:')\n",
    "print('Training Set:', len(X_train))\n",
    "print('Validation Set:', len(X_val))\n",
    "print('Test Set:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Set\n",
      "Percent \"Responded\": 0.14732142857142858\n",
      "Balanced Training Set\n",
      "Percent \"Responded\": 0.5\n"
     ]
    }
   ],
   "source": [
    "#Balance the training data set using SMOTE\n",
    "#create the SMOTE object\n",
    "sm = SMOTE(random_state=8)\n",
    "\n",
    "#create new training set with SMOTE object\n",
    "X_bal, y_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#Displays perccent of each class\n",
    "print('Initial Training Set')\n",
    "print('Percent \"Responded\":', y_train.sum()/len(y_train))\n",
    "print('Balanced Training Set')\n",
    "print('Percent \"Responded\":', y_bal.sum()/len(y_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>After using SMOTE the dataset is perfeclty balanced. This will improve the performance of the models in the next section.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h2>Create Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>For the following models, recall will be a very important metric. This is because we would rather have more False Positives (customers who will not respond to the marketing but was targeted anyway) than False Negatives (customers who would have responded to the add but were not targeted). For these reasons, a balance must be struck between accuracy of the model and the recall of the model.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.25, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Logistic Regression Model Accuracy: 0.7886904761904762\n",
      "Logistic Regression Model Recall: 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "#Create a Logistic Regression Model\n",
    "#Params to test in grid search\n",
    "lr_params = {'solver': ['liblinear'], 'penalty': ['l1'], 'C': [1.0, 0.5, 0.25]}\n",
    "\n",
    "#grid search\n",
    "lr_grid = GridSearchCV(LogisticRegression(), lr_params, cv=3, scoring='recall')\n",
    "\n",
    "#fit the grid to the training set\n",
    "lr_grid.fit(X_bal, y_bal)\n",
    "\n",
    "#ID the best model\n",
    "lr = lr_grid.best_estimator_\n",
    "\n",
    "#Display Best Parameters\n",
    "print('Best Parameters:', lr_grid.best_params_)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "lr_preds = lr.predict(X_val)\n",
    "lr_val_acc = accuracy_score(y_val, lr_preds)\n",
    "lr_val_rec = recall_score(y_val, lr_preds)\n",
    "print('Logistic Regression Model Accuracy:', lr_val_acc)\n",
    "print('Logistic Regression Model Recall:', lr_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Support Vector Machine</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Support Vector Machine Accuracy: 0.8273809523809523\n",
      "Support Vector Machine Recall: 0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "#Create a Support Vector machine\n",
    "#Params to test in grid search\n",
    "svm_params = {'kernel': ['poly', 'rbf'], 'C': [1.0, 0.5, 0.25], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "#grid search\n",
    "svm_grid = GridSearchCV(SVC(), svm_params, cv=3, scoring='recall')\n",
    "\n",
    "#fit the grid to the training set\n",
    "svm_grid.fit(X_bal, y_bal)\n",
    "\n",
    "#ID the best model\n",
    "svm = svm_grid.best_estimator_\n",
    "\n",
    "#Display Best Parameters\n",
    "print('Best Parameters:', svm_grid.best_params_)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "svm_preds = svm.predict(X_val)\n",
    "svm_val_acc = accuracy_score(y_val, svm_preds)\n",
    "svm_val_rec = recall_score(y_val, svm_preds)\n",
    "print('Support Vector Machine Accuracy:', svm_val_acc)\n",
    "print('Support Vector Machine Recall:', svm_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>K Nearest Neighbors</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "K Nearest Neighbors Accuracy: 0.7529761904761905\n",
      "K Nearest Neighbors Recall: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#Create a knn model\n",
    "#Params to test in grid search\n",
    "knn_params = {'n_neighbors': [7, 9, 11], 'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "             'weights': ['uniform', 'distance']}\n",
    "\n",
    "#grid search\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=3, scoring='recall')\n",
    "\n",
    "#fit the grid to the training set\n",
    "knn_grid.fit(X_bal, y_bal)\n",
    "\n",
    "#ID the best model\n",
    "knn = knn_grid.best_estimator_\n",
    "\n",
    "#Display Best Parameters\n",
    "print('Best Parameters:', knn_grid.best_params_)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "knn_preds = knn.predict(X_val)\n",
    "knn_val_acc = accuracy_score(y_val, knn_preds)\n",
    "knn_val_rec = recall_score(y_val, knn_preds)\n",
    "print('K Nearest Neighbors Accuracy:', knn_val_acc)\n",
    "print('K Nearest Neighbors Recall:', knn_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Naive Bayes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.6934523809523809\n",
      "Naive Bayes Machine Recall: 0.6481481481481481\n"
     ]
    }
   ],
   "source": [
    "#Create a naive bayes model\n",
    "nb = GaussianNB()\n",
    "\n",
    "#fit the model to the training set\n",
    "nb.fit(X_bal, y_bal)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "nb_preds = nb.predict(X_val)\n",
    "nb_val_acc = accuracy_score(y_val, nb_preds)\n",
    "nb_val_rec = recall_score(y_val, nb_preds)\n",
    "print('Naive Bayes Accuracy:', nb_val_acc)\n",
    "print('Naive Bayes Machine Recall:', nb_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gradient Boosting Tree</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'max_depth': 15, 'n_estimators': 250}\n",
      "Gradient Boosting Tree Accuracy: 0.8988095238095238\n",
      "Gradient Boosting Tree Recall: 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "#Create a xgboost model\n",
    "#Params to test in grid search\n",
    "xgb_params = {'n_estimators': [240, 250, 260], 'max_depth': [15, 16, 17],\n",
    "             'colsample_bytree': [0.6, 0.7, 0.8, 1.0]}\n",
    "\n",
    "#grid search\n",
    "xgb_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, verbosity=0), xgb_params, cv=3, \n",
    "                        scoring='recall')\n",
    "\n",
    "#fit the grid to the training set\n",
    "xgb_grid.fit(X_bal, y_bal)\n",
    "\n",
    "#ID the best model\n",
    "xgb = xgb_grid.best_estimator_\n",
    "\n",
    "#Display Best Parameters\n",
    "print('Best Parameters:', xgb_grid.best_params_)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "xgb_preds = xgb.predict(X_val)\n",
    "xgb_val_acc = accuracy_score(y_val, xgb_preds)\n",
    "xgb_val_rec = recall_score(y_val, xgb_preds)\n",
    "print('Gradient Boosting Tree Accuracy:', xgb_val_acc)\n",
    "print('Gradient Boosting Tree Recall:', xgb_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<h2>Ensemble the Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.8571428571428571\n",
      "Ensemble Model Recall: 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "#Create ensemble model of all the other models\n",
    "#list of models\n",
    "models = [('logistic_regression', lr), ('support vector machine', svm), \n",
    "        ('knn', knn), ('naive_bayes', nb), ('gradient_boost', xgb)]\n",
    "\n",
    "#Combine models\n",
    "ensemble_model = VotingClassifier(estimators=models)\n",
    "\n",
    "#fit the model on the training set\n",
    "ensemble_model.fit(X_bal, y_bal)\n",
    "\n",
    "#Display the metrics for the validation set\n",
    "ensemble_preds = ensemble_model.predict(X_val)\n",
    "ensemble_val_acc = accuracy_score(y_val, ensemble_preds)\n",
    "ensemble_val_rec = recall_score(y_val, ensemble_preds)\n",
    "print('Ensemble Model Accuracy:', ensemble_val_acc)\n",
    "print('Ensemble Model Recall:', ensemble_val_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>This model takes the predictions of the previous 5 models and will output the class with the highest amount of votes.\n",
    "    The ensemble models strikes a good balance between recall and accuracy (both around 85%). Now, let us see the results on the test set.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics\n",
      "Ensemble Model Accuracy: 0.8511904761904762\n",
      "Ensemble Model Recall: 0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "#Display the metrics of the Ensemble model on the test set\n",
    "test_preds = ensemble_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "test_rec = recall_score(y_test, test_preds)\n",
    "print('Test Set Metrics')\n",
    "print('Ensemble Model Accuracy:', test_acc)\n",
    "print('Ensemble Model Recall:', test_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h2>Conclusions</h2>\n",
    "\n",
    "<ul>\n",
    "    <li><strong>The final model's accuracy is 85% and recall is 75%.</strong> This is a reasonable balance between the two metrics and will allow the store to identify and target the majority of customers who will respond to marketing while not having to spend an excess of resources targeting large amounts of customers who will not respond. If the store was willing to spend a bit more on marketing, the ensemble model could be modified to identify customers who will respond to the add if 2 or more of the 5 weak models vote.</li>\n",
    "    <li><strong>This dataset may not be complex enough.</strong> Customers are complex. There are a variety of reasons why a customer would respond to marketing and the dataset used here only includes a small fraction of all variables that need to be considered. That being said, some more feature that could be useful if provided would be: what items are being marketed for each of the campaigns, times of year of purchases and marketing campaigns, the location of the store(s), and how each marketing campaign was presented to customers (web only?, catalog and web?).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Thank you for reading through this project and a special thanks to friends and family. :)</h5> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
